{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<h2 style = \"font-size:40px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> Celebrity Face Recognition using VGGFace Model </h2>\n",
        "<br>"
      ],
      "metadata": {
        "id": "68ezA_Jik7en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TzZnCLeFcwVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Celebrity.png](https://i.postimg.cc/5yp4715n/Celebrity.png)](https://postimg.cc/xNJV8w4z)"
      ],
      "metadata": {
        "id": "4V-3ToqQk7ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '0'></a>\n",
        "<h2 style = \"font-family: garamond; font-size: 40px; font-style: normal; letter-spcaing: 3px; background-color: #007580; color : #fed049; border-radius: 5px 5px; text-align:center; font-weight: bold\" >Table of Contents</h2>\n",
        "\n",
        "1. [Overview](#1.0)\n",
        "2. [Import the necessary libraries](#2.0)\n",
        "3. [Data Collection](#3.0)\n",
        "4. [Feature Engineering](#4.0)\n",
        "\t- [VGG Face model](#4.1)\n",
        "\t- [Generate embeddings for each image in the dataset](#4.2)\n",
        "\t- [Plot images and get distance between the pairs](#4.3)\n",
        "\t- [Create train and test sets](#4.4)\n",
        "\t- [Reduce dimensions using PCA](#4.5)\n",
        "5. [Model Building and Validation](#5.0)\n",
        "    - [Build a Machine Learning Classifier](#5.1)\n",
        "    - [Validate Celebrity Images](#5.2)\n",
        "6. [Conclusion](#6.0)"
      ],
      "metadata": {
        "id": "v3rZ5GR_k7eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '1.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 1. Overview </h2>"
      ],
      "metadata": {
        "id": "qjo7Xz64k7er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Description:\n",
        "\n",
        "In this hands-on project, the goal is to build a face identification model to recognize faces."
      ],
      "metadata": {
        "id": "p0H1NQo_OA8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Description:\n",
        "\n",
        "**Aligned Face Dataset from Pinterest**\n",
        "\n",
        "This dataset contains 17534 images for 100 people. All images are taken from 'Pinterest' and aligned using dlib library."
      ],
      "metadata": {
        "id": "aq0hfmhFk7er"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "\n",
        "In this problem, we use a pre-trained model trained on Face recognition to recognize similar faces. Here, we are particularly interested in recognizing whether two given faces are of the same person or not."
      ],
      "metadata": {
        "id": "9Ojdr5aFOO1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '2.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 2. Import the necessary libraries </h2>"
      ],
      "metadata": {
        "id": "ugpImMiWk7es"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# used to supress display of warnings\n",
        "import warnings\n",
        "\n",
        "from sklearn.metrics import precision_recall_curve,accuracy_score,f1_score,precision_score,recall_score"
      ],
      "metadata": {
        "id": "KrFFDQZDOov1",
        "_kg_hide-output": false,
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:05.045366Z",
          "iopub.execute_input": "2021-07-28T14:41:05.045734Z",
          "iopub.status.idle": "2021-07-28T14:41:05.976364Z",
          "shell.execute_reply.started": "2021-07-28T14:41:05.045654Z",
          "shell.execute_reply": "2021-07-28T14:41:05.975383Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting Options"
      ],
      "metadata": {
        "id": "-Lqmif0FOtpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# suppress display of warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4OdB5GLwOuSd",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:05.978314Z",
          "iopub.execute_input": "2021-07-28T14:41:05.978714Z",
          "iopub.status.idle": "2021-07-28T14:41:05.983327Z",
          "shell.execute_reply.started": "2021-07-28T14:41:05.978673Z",
          "shell.execute_reply": "2021-07-28T14:41:05.982101Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '3.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 3. Data Collection </h2>"
      ],
      "metadata": {
        "id": "98ZiSvKak7eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "source_dir=('/content/drive/MyDrive/105_classes_pins_dataset')"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:05.985896Z",
          "iopub.execute_input": "2021-07-28T14:41:05.986313Z",
          "iopub.status.idle": "2021-07-28T14:41:05.994778Z",
          "shell.execute_reply.started": "2021-07-28T14:41:05.986274Z",
          "shell.execute_reply": "2021-07-28T14:41:05.993928Z"
        },
        "trusted": true,
        "id": "Chjnq6unk7eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Function to load images </strong></p>\n",
        "- Define a function to load the images from the extracted folder and map each image with person id\n"
      ],
      "metadata": {
        "id": "lc-d5GUeVsyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IdentityMetadata():\n",
        "    def __init__(self, base, name, file):\n",
        "        self.base = base\n",
        "        # identity name\n",
        "        self.name = name\n",
        "        # image file name\n",
        "        self.file = file\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.image_path()\n",
        "\n",
        "    def image_path(self):\n",
        "        return os.path.join(self.base, self.name, self.file)\n",
        "\n",
        "def load_metadata(path):\n",
        "    metadata = []\n",
        "    for i in os.listdir(path):\n",
        "        for f in os.listdir(os.path.join(path, i)):\n",
        "            # Check file extension. Allow only jpg/jpeg' files.\n",
        "            ext = os.path.splitext(f)[1]\n",
        "            if ext == '.jpg' or ext == '.jpeg':\n",
        "                metadata.append(IdentityMetadata(path, i, f))\n",
        "    return np.array(metadata)\n",
        "\n",
        "# metadata = load_metadata('images')\n",
        "metadata = load_metadata(source_dir)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:05.997093Z",
          "iopub.execute_input": "2021-07-28T14:41:05.997415Z",
          "iopub.status.idle": "2021-07-28T14:41:12.976252Z",
          "shell.execute_reply.started": "2021-07-28T14:41:05.997374Z",
          "shell.execute_reply": "2021-07-28T14:41:12.975244Z"
        },
        "trusted": true,
        "id": "UxfU_w1zk7ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('metadata shape :', metadata.shape)"
      ],
      "metadata": {
        "id": "Kw4FaA-5WDld",
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:12.977661Z",
          "iopub.execute_input": "2021-07-28T14:41:12.978061Z",
          "iopub.status.idle": "2021-07-28T14:41:12.984091Z",
          "shell.execute_reply.started": "2021-07-28T14:41:12.978021Z",
          "shell.execute_reply": "2021-07-28T14:41:12.982761Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Define a function to load an image </strong></p>\n",
        "- Define a function to load image from the metadata"
      ],
      "metadata": {
        "id": "-cluKzrJWKii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "def load_image(path):\n",
        "    img = cv2.imread(path, 1)\n",
        "    # OpenCV loads images with color channels\n",
        "    # in BGR order. So we need to reverse them\n",
        "    return img[...,::-1]"
      ],
      "metadata": {
        "id": "4vC0Iv-hWLOf",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:13.015338Z",
          "iopub.execute_input": "2021-07-28T14:41:13.015840Z",
          "iopub.status.idle": "2021-07-28T14:41:13.160412Z",
          "shell.execute_reply.started": "2021-07-28T14:41:13.015784Z",
          "shell.execute_reply": "2021-07-28T14:41:13.159582Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Load a sample image</strong></p>\n",
        "- Load one image using the function \"load_image\""
      ],
      "metadata": {
        "id": "qHPJIdPMWRMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_image('/content/drive/MyDrive/105_classes_pins_dataset/pins_Emilia Clarke/Emilia Clarke247_998.jpg')"
      ],
      "metadata": {
        "id": "CswOmjUXWTC0",
        "_kg_hide-input": false,
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:13.168069Z",
          "iopub.execute_input": "2021-07-28T14:41:13.168423Z",
          "iopub.status.idle": "2021-07-28T14:41:13.206446Z",
          "shell.execute_reply.started": "2021-07-28T14:41:13.168386Z",
          "shell.execute_reply": "2021-07-28T14:41:13.205640Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 4. Feature Engineering </h2>"
      ],
      "metadata": {
        "id": "QzCqBuFkk7ey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.1'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 4.1 VGG Face model </strong></p>\n",
        "- Here we are giving you the predefined model for VGG face"
      ],
      "metadata": {
        "id": "PbhVJAQuWZ_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import ZeroPadding2D, Convolution2D, MaxPooling2D, Dropout, Flatten, Activation\n",
        "\n",
        "def vgg_face():\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Convolution2D(2622, (1, 1)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Activation('softmax'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "2Fa7Lw3hWafy",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:13.207778Z",
          "iopub.execute_input": "2021-07-28T14:41:13.208172Z",
          "iopub.status.idle": "2021-07-28T14:41:17.048294Z",
          "shell.execute_reply.started": "2021-07-28T14:41:13.208133Z",
          "shell.execute_reply": "2021-07-28T14:41:17.047427Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Load the model </strong></p>\n",
        "\n",
        "- Load the model defined above\n",
        "- Then load the given weight file named \"vgg_face_weights.h5\""
      ],
      "metadata": {
        "id": "7j9j4tYyWe3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = vgg_face()\n",
        "\n",
        "model.load_weights('../input/vgg-face-weights/vgg_face_weights.h5')"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:17.049494Z",
          "iopub.execute_input": "2021-07-28T14:41:17.049806Z",
          "iopub.status.idle": "2021-07-28T14:41:27.572295Z",
          "shell.execute_reply.started": "2021-07-28T14:41:17.049773Z",
          "shell.execute_reply": "2021-07-28T14:41:27.571401Z"
        },
        "trusted": true,
        "id": "VkEF5beXk7ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Get vgg_face_descriptor </strong></p>"
      ],
      "metadata": {
        "id": "AuuvpN6xWrO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0], model.layers[-2]"
      ],
      "metadata": {
        "id": "GB7STOoqWrs9",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:27.573668Z",
          "iopub.execute_input": "2021-07-28T14:41:27.574015Z",
          "iopub.status.idle": "2021-07-28T14:41:27.581308Z",
          "shell.execute_reply.started": "2021-07-28T14:41:27.573965Z",
          "shell.execute_reply": "2021-07-28T14:41:27.579980Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
      ],
      "metadata": {
        "id": "Ez6M-euqWuR3",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:27.583066Z",
          "iopub.execute_input": "2021-07-28T14:41:27.583477Z",
          "iopub.status.idle": "2021-07-28T14:41:27.598535Z",
          "shell.execute_reply.started": "2021-07-28T14:41:27.583436Z",
          "shell.execute_reply": "2021-07-28T14:41:27.597552Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(vgg_face_descriptor)"
      ],
      "metadata": {
        "id": "8bGCv4GBWweV",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:27.600023Z",
          "iopub.execute_input": "2021-07-28T14:41:27.600644Z",
          "iopub.status.idle": "2021-07-28T14:41:27.607102Z",
          "shell.execute_reply.started": "2021-07-28T14:41:27.600601Z",
          "shell.execute_reply": "2021-07-28T14:41:27.605828Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_face_descriptor.inputs, vgg_face_descriptor.outputs"
      ],
      "metadata": {
        "id": "trmNlTvnWyEz",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:27.609109Z",
          "iopub.execute_input": "2021-07-28T14:41:27.609540Z",
          "iopub.status.idle": "2021-07-28T14:41:27.617446Z",
          "shell.execute_reply.started": "2021-07-28T14:41:27.609499Z",
          "shell.execute_reply": "2021-07-28T14:41:27.616127Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.2'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 4.2 Generate embeddings for each image in the dataset </strong></p>\n",
        "\n",
        "- Given below is an example to load the first image in the metadata and get its embedding vector from the pre-trained model."
      ],
      "metadata": {
        "id": "yc4uU9V2W2-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get embedding vector for first image in the metadata using the pre-trained model\n",
        "img_path = metadata[0].image_path()\n",
        "img = load_image(img_path)\n",
        "\n",
        "# Normalising pixel values from [0-255] to [0-1]: scale RGB values to interval [0,1]\n",
        "img = (img / 255.).astype(np.float32)\n",
        "img = cv2.resize(img, dsize = (224,224))\n",
        "print(img.shape)\n",
        "\n",
        "# Obtain embedding vector for an image\n",
        "# Get the embedding vector for the above image using vgg_face_descriptor model and print the shape\n",
        "embedding_vector = vgg_face_descriptor.predict(np.expand_dims(img, axis=0))[0]\n",
        "print(embedding_vector.shape)"
      ],
      "metadata": {
        "id": "XNjo6pZ5W3fR",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:27.619119Z",
          "iopub.execute_input": "2021-07-28T14:41:27.619557Z",
          "iopub.status.idle": "2021-07-28T14:41:34.129148Z",
          "shell.execute_reply.started": "2021-07-28T14:41:27.619517Z",
          "shell.execute_reply": "2021-07-28T14:41:34.128205Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector[0], type(embedding_vector), type(embedding_vector[0])"
      ],
      "metadata": {
        "id": "7E_lGB43W-y1",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:34.132171Z",
          "iopub.execute_input": "2021-07-28T14:41:34.132445Z",
          "iopub.status.idle": "2021-07-28T14:41:34.149048Z",
          "shell.execute_reply.started": "2021-07-28T14:41:34.132417Z",
          "shell.execute_reply": "2021-07-28T14:41:34.140721Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vector[2], embedding_vector[98], embedding_vector[-2]"
      ],
      "metadata": {
        "id": "Sph5OmpvW_Qh",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:34.152935Z",
          "iopub.execute_input": "2021-07-28T14:41:34.153260Z",
          "iopub.status.idle": "2021-07-28T14:41:34.160830Z",
          "shell.execute_reply.started": "2021-07-28T14:41:34.153229Z",
          "shell.execute_reply": "2021-07-28T14:41:34.160024Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Generate embeddings for all images </strong></p>\n",
        "\n",
        "- Write code to iterate through metadata and create embeddings for each image using `vgg_face_descriptor.predict()` and store in a list with name `embeddings`\n",
        "\n",
        "- If there is any error in reading any image in the dataset, fill the emebdding vector of that image with 2622-zeroes as the final embedding from the model is of length 2622."
      ],
      "metadata": {
        "id": "MfRb057gXEId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_images = len(metadata)\n",
        "\n",
        "print('total_images :', total_images)"
      ],
      "metadata": {
        "id": "2p4wp8hHXHN1",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:34.162320Z",
          "iopub.execute_input": "2021-07-28T14:41:34.163060Z",
          "iopub.status.idle": "2021-07-28T14:41:34.172852Z",
          "shell.execute_reply.started": "2021-07-28T14:41:34.163020Z",
          "shell.execute_reply": "2021-07-28T14:41:34.171510Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.zeros((metadata.shape[0], 2622))\n",
        "for i, m in enumerate(metadata):\n",
        "    img_path = metadata[i].image_path()\n",
        "    img = load_image(img_path)\n",
        "    img = (img / 255.).astype(np.float32)\n",
        "    img = cv2.resize(img, dsize = (224,224))\n",
        "    embedding_vector = vgg_face_descriptor.predict(np.expand_dims(img, axis=0))[0]\n",
        "    embeddings[i]=embedding_vector"
      ],
      "metadata": {
        "id": "XadxhKHnYAIY",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T14:41:34.174393Z",
          "iopub.execute_input": "2021-07-28T14:41:34.175070Z",
          "iopub.status.idle": "2021-07-28T15:03:37.649174Z",
          "shell.execute_reply.started": "2021-07-28T14:41:34.175035Z",
          "shell.execute_reply": "2021-07-28T15:03:37.648313Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('embeddings shape :', embeddings.shape)"
      ],
      "metadata": {
        "id": "DLQqO9i-YEZG",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:37.650551Z",
          "iopub.execute_input": "2021-07-28T15:03:37.650899Z",
          "iopub.status.idle": "2021-07-28T15:03:37.657291Z",
          "shell.execute_reply.started": "2021-07-28T15:03:37.650863Z",
          "shell.execute_reply": "2021-07-28T15:03:37.655479Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0], embeddings[988], embeddings[988].shape"
      ],
      "metadata": {
        "id": "YGTD0DdjYE1C",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:37.662793Z",
          "iopub.execute_input": "2021-07-28T15:03:37.663339Z",
          "iopub.status.idle": "2021-07-28T15:03:37.670594Z",
          "shell.execute_reply.started": "2021-07-28T15:03:37.663303Z",
          "shell.execute_reply": "2021-07-28T15:03:37.669444Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[8275]"
      ],
      "metadata": {
        "id": "aqzvAKFWYGZm",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:37.673118Z",
          "iopub.execute_input": "2021-07-28T15:03:37.673614Z",
          "iopub.status.idle": "2021-07-28T15:03:37.681790Z",
          "shell.execute_reply.started": "2021-07-28T15:03:37.673577Z",
          "shell.execute_reply": "2021-07-28T15:03:37.680650Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Function to calculate distance between given 2 pairs of images </strong></p>\n",
        "\n",
        "- Consider distance metric as \"Squared L2 distance\"\n",
        "- Squared l2 distance between 2 points (x1, y1) and (x2, y2) = (x1-x2)^2 + (y1-y2)^2"
      ],
      "metadata": {
        "id": "e8rTvQOKYLvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distance(emb1, emb2):\n",
        "    return np.sum(np.square(emb1 - emb2))"
      ],
      "metadata": {
        "id": "Bi-H43_ZYMe-",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:37.683499Z",
          "iopub.execute_input": "2021-07-28T15:03:37.684091Z",
          "iopub.status.idle": "2021-07-28T15:03:37.689217Z",
          "shell.execute_reply.started": "2021-07-28T15:03:37.684053Z",
          "shell.execute_reply": "2021-07-28T15:03:37.688133Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.3'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 4.3 Plot images and get distance between the pairs </strong></p>\n",
        "\n",
        "- 900, 901 and 900, 1001\n",
        "- 1100, 1101 and 1100, 1300\n",
        "- 1407, 1408 and 1408, 1602"
      ],
      "metadata": {
        "id": "h0w9kREXk7e-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_pair(idx1, idx2):\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.suptitle(f'Distance between {idx1} & {idx2}= {distance(embeddings[idx1], embeddings[idx2]):.2f}')\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(load_image(metadata[idx1].image_path()))\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(load_image(metadata[idx2].image_path()));\n",
        "\n",
        "show_pair(900, 901)\n",
        "show_pair(900, 1001)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:37.690775Z",
          "iopub.execute_input": "2021-07-28T15:03:37.691315Z",
          "iopub.status.idle": "2021-07-28T15:03:38.311689Z",
          "shell.execute_reply.started": "2021-07-28T15:03:37.691232Z",
          "shell.execute_reply": "2021-07-28T15:03:38.310750Z"
        },
        "trusted": true,
        "id": "SCQdCaljk7e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_pair(1100, 1101)\n",
        "show_pair(1100, 1300)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:38.313159Z",
          "iopub.execute_input": "2021-07-28T15:03:38.313502Z",
          "iopub.status.idle": "2021-07-28T15:03:38.867818Z",
          "shell.execute_reply.started": "2021-07-28T15:03:38.313464Z",
          "shell.execute_reply": "2021-07-28T15:03:38.866845Z"
        },
        "trusted": true,
        "id": "43JbE9r8k7e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_pair(1407, 1408)\n",
        "show_pair(1408, 1602)"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:38.869226Z",
          "iopub.execute_input": "2021-07-28T15:03:38.869564Z",
          "iopub.status.idle": "2021-07-28T15:03:39.462289Z",
          "shell.execute_reply.started": "2021-07-28T15:03:38.869529Z",
          "shell.execute_reply": "2021-07-28T15:03:39.461292Z"
        },
        "trusted": true,
        "id": "OJAeamgUk7e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.4'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 4.4 Create train and test sets </strong></p>\n",
        "- Create X_train, X_test and y_train, y_test\n",
        "- Use train_idx to seperate out training features and labels\n",
        "- Use test_idx to seperate out testing features and labels"
      ],
      "metadata": {
        "id": "Bf-m72YcYkFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx = np.arange(metadata.shape[0]) % 9 != 0     #every 9th example goes in test data and rest go in train data\n",
        "test_idx = np.arange(metadata.shape[0]) % 9 == 0\n",
        "\n",
        "# one half as train examples of 10 identities\n",
        "X_train = embeddings[train_idx]\n",
        "\n",
        "# another half as test examples of 10 identities\n",
        "X_test = embeddings[test_idx]\n",
        "targets = np.array([m.name for m in metadata])\n",
        "\n",
        "#train labels\n",
        "y_train = targets[train_idx]\n",
        "\n",
        "#test labels\n",
        "y_test = targets[test_idx]"
      ],
      "metadata": {
        "id": "CQ0L_W_NYn6a",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.463682Z",
          "iopub.execute_input": "2021-07-28T15:03:39.464037Z",
          "iopub.status.idle": "2021-07-28T15:03:39.593774Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.463982Z",
          "shell.execute_reply": "2021-07-28T15:03:39.592886Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train shape : ({0},{1})'.format(X_train.shape[0], X_train.shape[1]))\n",
        "print('y_train shape : ({0},)'.format(y_train.shape[0]))\n",
        "print('X_test shape : ({0},{1})'.format(X_test.shape[0], X_test.shape[1]))\n",
        "print('y_test shape : ({0},)'.format(y_test.shape[0]))"
      ],
      "metadata": {
        "id": "rXVkY4hgY0TR",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.595295Z",
          "iopub.execute_input": "2021-07-28T15:03:39.595668Z",
          "iopub.status.idle": "2021-07-28T15:03:39.602840Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.595629Z",
          "shell.execute_reply": "2021-07-28T15:03:39.601952Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[0], y_train[988]"
      ],
      "metadata": {
        "id": "BxOrg348ZKdw",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.604202Z",
          "iopub.execute_input": "2021-07-28T15:03:39.604766Z",
          "iopub.status.idle": "2021-07-28T15:03:39.614537Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.604727Z",
          "shell.execute_reply": "2021-07-28T15:03:39.613436Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(np.unique(y_test)), len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "1-JkPALvZND2",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.615860Z",
          "iopub.execute_input": "2021-07-28T15:03:39.616465Z",
          "iopub.status.idle": "2021-07-28T15:03:39.631136Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.616424Z",
          "shell.execute_reply": "2021-07-28T15:03:39.630254Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Encode the Labels </strong></p>\n",
        "- Encode the targets\n",
        "- Use LabelEncoder"
      ],
      "metadata": {
        "id": "yKWJJX5SZRqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train_encoded = le.fit_transform(y_train)"
      ],
      "metadata": {
        "id": "TFpZqDkwZWoO",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.632180Z",
          "iopub.execute_input": "2021-07-28T15:03:39.632440Z",
          "iopub.status.idle": "2021-07-28T15:03:39.644841Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.632414Z",
          "shell.execute_reply": "2021-07-28T15:03:39.643986Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(le.classes_)\n",
        "y_test_encoded = le.transform(y_test)"
      ],
      "metadata": {
        "id": "aZZtjuc6ZaKE",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.647743Z",
          "iopub.execute_input": "2021-07-28T15:03:39.648036Z",
          "iopub.status.idle": "2021-07-28T15:03:39.658650Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.647986Z",
          "shell.execute_reply": "2021-07-28T15:03:39.657621Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_train_encoded : ', y_train_encoded)\n",
        "print('y_test_encoded : ', y_test_encoded)"
      ],
      "metadata": {
        "id": "LPOa56Z7Zcat",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.659953Z",
          "iopub.execute_input": "2021-07-28T15:03:39.660366Z",
          "iopub.status.idle": "2021-07-28T15:03:39.668297Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.660328Z",
          "shell.execute_reply": "2021-07-28T15:03:39.666955Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p style = \"font-size:20px; color: #007580 \"><strong> Standardize the feature values </strong></p>\n",
        "- Scale the features using StandardScaler"
      ],
      "metadata": {
        "id": "kv0eLwomZd9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standarize features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "9rBEhgxeZhCF",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:39.670305Z",
          "iopub.execute_input": "2021-07-28T15:03:39.670788Z",
          "iopub.status.idle": "2021-07-28T15:03:40.572596Z",
          "shell.execute_reply.started": "2021-07-28T15:03:39.670749Z",
          "shell.execute_reply": "2021-07-28T15:03:40.571741Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_std = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "7-0t0jGRZlC9",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:40.573875Z",
          "iopub.execute_input": "2021-07-28T15:03:40.574235Z",
          "iopub.status.idle": "2021-07-28T15:03:40.609086Z",
          "shell.execute_reply.started": "2021-07-28T15:03:40.574199Z",
          "shell.execute_reply": "2021-07-28T15:03:40.608237Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '4.5'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 4.5 Reduce dimensions using PCA </strong></p>\n",
        "- Reduce feature dimensions using Principal Component Analysis\n",
        "- Set the parameter n_components=128"
      ],
      "metadata": {
        "id": "6kOcBHr0Zpwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('X_train_std shape : ({0},{1})'.format(X_train_std.shape[0], X_train_std.shape[1]))\n",
        "print('y_train_encoded shape : ({0},)'.format(y_train_encoded.shape[0]))\n",
        "print('X_test_std shape : ({0},{1})'.format(X_test_std.shape[0], X_test_std.shape[1]))\n",
        "print('y_test_encoded shape : ({0},)'.format(y_test_encoded.shape[0]))"
      ],
      "metadata": {
        "id": "XBoVS9mwZrIB",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:40.610336Z",
          "iopub.execute_input": "2021-07-28T15:03:40.610717Z",
          "iopub.status.idle": "2021-07-28T15:03:40.617414Z",
          "shell.execute_reply.started": "2021-07-28T15:03:40.610680Z",
          "shell.execute_reply": "2021-07-28T15:03:40.616434Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=128)\n",
        "X_train_pca = pca.fit_transform(X_train_std)\n",
        "X_test_pca = pca.transform(X_test_std)"
      ],
      "metadata": {
        "id": "C_dyk-k1ZtPh",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:40.618666Z",
          "iopub.execute_input": "2021-07-28T15:03:40.619170Z",
          "iopub.status.idle": "2021-07-28T15:03:46.576794Z",
          "shell.execute_reply.started": "2021-07-28T15:03:40.619135Z",
          "shell.execute_reply": "2021-07-28T15:03:46.575811Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '5.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 5. Model Building and Validation </h2>"
      ],
      "metadata": {
        "id": "irKclnxek7fD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '5.1'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 5.1 Build a Machine Learning Classifier </strong></p>\n",
        "\n",
        "- Use SVM Classifier to predict the person in the given image\n",
        "- Fit the classifier and print the score"
      ],
      "metadata": {
        "id": "k8z1p40zZ0D5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC(C=5., gamma=0.001)\n",
        "clf.fit(X_train_pca, y_train_encoded)"
      ],
      "metadata": {
        "id": "yt__t5aOZ1aC",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:03:46.578278Z",
          "iopub.execute_input": "2021-07-28T15:03:46.578842Z",
          "iopub.status.idle": "2021-07-28T15:04:27.432866Z",
          "shell.execute_reply.started": "2021-07-28T15:03:46.578804Z",
          "shell.execute_reply": "2021-07-28T15:04:27.431963Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = clf.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "o3LsEI_kZ8CQ",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:27.434288Z",
          "iopub.execute_input": "2021-07-28T15:04:27.434673Z",
          "iopub.status.idle": "2021-07-28T15:04:34.268875Z",
          "shell.execute_reply.started": "2021-07-28T15:04:27.434633Z",
          "shell.execute_reply": "2021-07-28T15:04:34.267938Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_predict : ',y_predict)\n",
        "print('y_test_encoded : ',y_test_encoded)"
      ],
      "metadata": {
        "id": "D0HGisqUZ8dT",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.270237Z",
          "iopub.execute_input": "2021-07-28T15:04:34.270862Z",
          "iopub.status.idle": "2021-07-28T15:04:34.277148Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.270822Z",
          "shell.execute_reply": "2021-07-28T15:04:34.275989Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict_encoded = le.inverse_transform(y_predict)"
      ],
      "metadata": {
        "id": "7hbTE95ZZ-q0",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.278928Z",
          "iopub.execute_input": "2021-07-28T15:04:34.279348Z",
          "iopub.status.idle": "2021-07-28T15:04:34.289249Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.279312Z",
          "shell.execute_reply": "2021-07-28T15:04:34.288378Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_predict_encoded : ',y_predict_encoded)"
      ],
      "metadata": {
        "id": "3e-O8kKCaBoE",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.290767Z",
          "iopub.execute_input": "2021-07-28T15:04:34.291208Z",
          "iopub.status.idle": "2021-07-28T15:04:34.299400Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.291169Z",
          "shell.execute_reply": "2021-07-28T15:04:34.298031Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_predict shape : ', y_predict.shape)\n",
        "print('y_test_encoded shape : ', y_test_encoded.shape)"
      ],
      "metadata": {
        "id": "L4LUg-XnaDTK",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.301136Z",
          "iopub.execute_input": "2021-07-28T15:04:34.301735Z",
          "iopub.status.idle": "2021-07-28T15:04:34.308084Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.301699Z",
          "shell.execute_reply": "2021-07-28T15:04:34.306938Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_encoded[32:49]"
      ],
      "metadata": {
        "id": "1OxI-H7naFct",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.309942Z",
          "iopub.execute_input": "2021-07-28T15:04:34.310904Z",
          "iopub.status.idle": "2021-07-28T15:04:34.319151Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.310864Z",
          "shell.execute_reply": "2021-07-28T15:04:34.318095Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the classification accuracy\n",
        "accuracy_score(y_test_encoded, y_predict)"
      ],
      "metadata": {
        "id": "zKgLPs4naHLl",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.320527Z",
          "iopub.execute_input": "2021-07-28T15:04:34.321199Z",
          "iopub.status.idle": "2021-07-28T15:04:34.329952Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.321148Z",
          "shell.execute_reply": "2021-07-28T15:04:34.329091Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Score: 96.455%**"
      ],
      "metadata": {
        "id": "BgJALEo1k7fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '5.2'></a>\n",
        "<p style = \"font-size:20px; color: #007580 \"><strong> 5.2 Validate Celebrity Images </strong></p>\n",
        "\n",
        "- Take  401th  image from test set and plot the image\n",
        "- Report to which person(folder name in dataset) the image belongs to"
      ],
      "metadata": {
        "id": "va7T63HCk7fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 401\n",
        "\n",
        "example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
        "example_prediction = y_predict[example_idx]\n",
        "example_identity =  y_predict_encoded[example_idx]\n",
        "\n",
        "plt.imshow(example_image)\n",
        "plt.title(f'Identified as {example_identity}');"
      ],
      "metadata": {
        "id": "ULCqw6joaP-W",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.332170Z",
          "iopub.execute_input": "2021-07-28T15:04:34.332810Z",
          "iopub.status.idle": "2021-07-28T15:04:34.513026Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.332772Z",
          "shell.execute_reply": "2021-07-28T15:04:34.512242Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 900\n",
        "\n",
        "example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
        "example_prediction = y_predict[example_idx]\n",
        "example_identity =  y_predict_encoded[example_idx]\n",
        "\n",
        "plt.imshow(example_image)\n",
        "plt.title(f'Identified as {example_identity}');"
      ],
      "metadata": {
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.514285Z",
          "iopub.execute_input": "2021-07-28T15:04:34.514613Z",
          "iopub.status.idle": "2021-07-28T15:04:34.696251Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.514577Z",
          "shell.execute_reply": "2021-07-28T15:04:34.695286Z"
        },
        "trusted": true,
        "id": "JOZXdLdzk7fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = 317\n",
        "\n",
        "example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
        "example_prediction = y_predict[example_idx]\n",
        "example_identity =  y_predict_encoded[example_idx]\n",
        "\n",
        "plt.imshow(example_image)\n",
        "plt.title(f'Identified as {example_identity}');"
      ],
      "metadata": {
        "id": "8Qkx_VyeaXUf",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.697659Z",
          "iopub.execute_input": "2021-07-28T15:04:34.697989Z",
          "iopub.status.idle": "2021-07-28T15:04:34.879965Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.697953Z",
          "shell.execute_reply": "2021-07-28T15:04:34.878947Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_idx = -27\n",
        "\n",
        "example_image = load_image(metadata[test_idx][example_idx].image_path())\n",
        "example_prediction = y_predict[example_idx]\n",
        "example_identity =  y_predict_encoded[example_idx]\n",
        "\n",
        "plt.imshow(example_image)\n",
        "plt.title(f'Identified as {example_identity}');"
      ],
      "metadata": {
        "id": "BGlbsZpIaZqN",
        "_kg_hide-input": false,
        "execution": {
          "iopub.status.busy": "2021-07-28T15:04:34.881437Z",
          "iopub.execute_input": "2021-07-28T15:04:34.881817Z",
          "iopub.status.idle": "2021-07-28T15:04:35.063912Z",
          "shell.execute_reply.started": "2021-07-28T15:04:34.881778Z",
          "shell.execute_reply": "2021-07-28T15:04:35.062964Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = '6.0'></a>\n",
        "<h2 style = \"font-size:35px; font-family:Garamond ; font-weight : normal; background-color: #007580; color :#fed049   ; text-align: center; border-radius: 5px 5px; padding: 5px\"> 6. Conclusion </h2>"
      ],
      "metadata": {
        "id": "VqTMEwbok7fJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. This dataset contains 17534 images for 100 people. All images are taken from 'Pinterest' and aligned using dlib library.\n",
        "2. Generated embeddings for all images using pre-trained VGG Face model.\n",
        "3. Used \"Squared L2 distance\" to calculate the distance between given 2 pairs of images.\n",
        "4. Encoded the target variables, standardize the features and reduced dimensions using PCA.\n",
        "5. Used SVM classifier to predict the celebrity in a given image and achived a 96.455% accuracy.\n",
        "\n",
        "- Reference Link for Template used in this notebook - https://www.kaggle.com/bhuvanchennoju/ancient-roots-of-agriculture-a-data-overview\n",
        "\n",
        "<p style = \"font-size:30px; color: #007580 ;background-color:  ; text-align: left; border-radius: 5px 5px; padding: 5px\" ><strong> Thanks for reading </strong></p>"
      ],
      "metadata": {
        "id": "f0GZKjglk7fJ"
      }
    }
  ]
}